import streamlit as st
from dataclasses import dataclass
from typing import List, Dict, Any
import uuid
import json

# =========================
# æ•°æ®ç»“æ„
# =========================

@dataclass
class TextUnit:
    id: str
    text: str


@dataclass
class TheoryExplorationResult:
    model_name: str
    identified_constructs: List[Dict[str, Any]]
    notes: str


@dataclass
class SynthesisResult:
    synthesized_constructs: List[Dict[str, Any]]
    hypotheses: List[str]


# =========================
# Step 1: è¾“å…¥å¤„ç†
# =========================

def load_text_units(raw_text: str) -> List[TextUnit]:
    """
    å°†è¾“å…¥æ–‡æœ¬æ‹†åˆ†ä¸ºæœ€å°åˆ†æå•å…ƒï¼ˆæŒ‰è¡Œï¼‰
    """
    lines = [line.strip() for line in raw_text.split("\n") if line.strip()]
    return [
        TextUnit(id=str(uuid.uuid4()), text=line)
        for line in lines
    ]


# =========================
# Step 2: ç‹¬ç«‹ç†è®ºæ¢ç´¢ï¼ˆå ä½ï¼‰
# =========================

def explore_theory_with_model(
    model_name: str,
    text_units: List[TextUnit]
) -> TheoryExplorationResult:
    """
    å•æ¨¡å‹ theory-guided construct exploration
    ï¼ˆè¿™é‡Œæ˜¯ mockï¼Œåç»­å¯æ¥ LLM APIï¼‰
    """

    constructs = [
        {
            "construct_name": "Perceived Helpfulness",
            "theoretical_origin": "Service-Dominant Logic",
            "behavioral_indicators": [
                "proactive clarification",
                "anticipation of user needs"
            ],
            "example_text_unit_ids": [tu.id for tu in text_units[:2]]
        }
    ]

    notes = (
        f"{model_name} independently explored marketing and sales theories "
        f"and grounded constructs in conversational behaviors."
    )

    return TheoryExplorationResult(
        model_name=model_name,
        identified_constructs=constructs,
        notes=notes
    )


# =========================
# Step 3: Judge Model ç»¼åˆï¼ˆå ä½ï¼‰
# =========================

def synthesize_with_judge_model(
    results: List[TheoryExplorationResult]
) -> SynthesisResult:
    """
    Judge modelï¼šå¯¹é½æ„å¿µã€æ¶ˆè§£å‘½åå·®å¼‚ã€ç”Ÿæˆå‡è®¾
    """

    synthesized_constructs = [
        {
            "construct_name": "Perceived Helpfulness",
            "merged_from_models": [r.model_name for r in results],
            "definition": (
                "The extent to which the agentâ€™s responses reduce user effort "
                "and increase decision clarity."
            ),
            "empirical_observability": "High"
        }
    ]

    hypotheses = [
        "H1: Early demonstrations of perceived helpfulness increase later conversational engagement.",
        "H2: Proactive explanations before persuasive attempts increase user trust signals."
    ]

    return SynthesisResult(
        synthesized_constructs=synthesized_constructs,
        hypotheses=hypotheses
    )


# =========================
# Streamlit UI
# =========================

st.set_page_config(
    page_title="Theory-Guided Construct Exploration",
    layout="wide"
)

st.title("ğŸ§  Theory-Guided Construct Exploration App")
st.markdown(
    """
This app operationalizes **theory-guided construct exploration** for conversational sales data.

**Workflow**
1. Upload or paste conversational text  
2. Independent theory exploration by multiple models  
3. Judge model synthesis  
4. Generation of testable hypotheses  
"""
)

# -------- è¾“å…¥åŒºåŸŸ --------
st.subheader("1ï¸âƒ£ Input Conversational Text")

raw_text = st.text_area(
    "Paste conversational text (one utterance per line):",
    height=200
)

# -------- è¿è¡ŒæŒ‰é’® --------
run_button = st.button("Run Theory Exploration")

# -------- ä¸»æµç¨‹ --------
if run_button and raw_text.strip():

    # Step 1
    text_units = load_text_units(raw_text)

    st.success(f"Loaded {len(text_units)} text units.")

    # Step 2
    with st.spinner("Running independent theory exploration..."):
        result_a = explore_theory_with_model("LLM_A", text_units)
        result_b = explore_theory_with_model("LLM_B", text_units)

    # Step 3
    with st.spinner("Synthesizing constructs with judge model..."):
        synthesis = synthesize_with_judge_model([result_a, result_b])

    # -------- è¾“å‡º --------
    st.subheader("2ï¸âƒ£ Independent Model Explorations")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**Model A Output**")
        st.json(result_a.__dict__)

    with col2:
        st.markdown("**Model B Output**")
        st.json(result_b.__dict__)

    st.subheader("3ï¸âƒ£ Judge Model Synthesis")

    st.markdown("**Synthesized Constructs**")
    st.json(synthesis.synthesized_constructs)

    st.markdown("**Generated Hypotheses**")
    for h in synthesis.hypotheses:
        st.write("-", h)

    # -------- å¯å¤ç°å¯¼å‡º --------
    st.subheader("4ï¸âƒ£ Export Results")

    export_data = {
        "text_units": [tu.__dict__ for tu in text_units],
        "independent_explorations": [
            result_a.__dict__,
            result_b.__dict__
        ],
        "synthesis": synthesis.__dict__
    }

    st.download_button(
        label="Download Results as JSON",
        data=json.dumps(export_data, indent=2),
        file_name="theory_exploration_results.json",
        mime="application/json"
    )

elif run_button:
    st.warning("Please paste some conversational text before running.")
